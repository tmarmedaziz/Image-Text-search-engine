{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YgOkRZkKp3qg"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from feature_extractor import FeatureExtractor\n",
    "import urllib.request\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import requests\n",
    "import numpy as np\n",
    "from io import BytesIO, StringIO\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creation of an image generator from the csv to load it in a light way**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "tV63TPqEsnIu"
   },
   "outputs": [],
   "source": [
    "class My_Custom_Generator(tf.keras.utils.Sequence) :\n",
    "    \n",
    "  \n",
    "    def __init__(self, image_filenames, batch_size) :\n",
    "        self.image_filenames = image_filenames\n",
    "        self.batch_size = batch_size\n",
    "        self.empty_images = []\n",
    "      \n",
    "    def util_func(self, img_url):\n",
    "        try:\n",
    "              return Image.open(BytesIO(requests.get(img_url).content))\n",
    "        except:\n",
    "              self.empty_images.append(img_url)\n",
    "    \n",
    "    \n",
    "    def __len__(self) :\n",
    "        return int((np.ceil(len(self.image_filenames) / float(self.batch_size))).astype(np.int))\n",
    "  \n",
    "  \n",
    "    def __getitem__(self, idx) :\n",
    "            batch_x = self.image_filenames[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "            \n",
    "            return np.array([ (self.util_func(file_name), file_name) for file_name in batch_x if self.util_func(file_name)!=None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initiation of the feature extractor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pWwuAhLZQPeP",
    "outputId": "2bab13ea-9f2d-4acb-876f-f8e676caee11"
   },
   "outputs": [],
   "source": [
    "fe = FeatureExtractor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**feature extractor with storing the dataframe each batch (sometimes, due to an unknown error, the system is blocked and all data is lost)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python38\\lib\\site-packages\\pandas\\core\\frame.py:3645: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self[col] = value\n",
      "C:\\Users\\AIM2021\\AppData\\Local\\Temp/ipykernel_3412/3607583605.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return int((np.ceil(len(self.image_filenames) / float(self.batch_size))).astype(np.int))\n",
      "Executed task:   0%|                                                                           | 0/883 [00:00<?, ?it/s]C:\\Users\\AIM2021\\AppData\\Local\\Temp/ipykernel_3412/3607583605.py:23: FutureWarning: The input object of type 'JpegImageFile' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'JpegImageFile', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  return np.array([ (self.util_func(file_name), file_name) for file_name in batch_x if self.util_func(file_name)!=None])\n",
      "C:\\Users\\AIM2021\\AppData\\Local\\Temp/ipykernel_3412/3607583605.py:23: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array([ (self.util_func(file_name), file_name) for file_name in batch_x if self.util_func(file_name)!=None])\n",
      "Executed task:   1%|â–                                                               | 6/883 [07:33<19:03:53, 78.26s/it]"
     ]
    }
   ],
   "source": [
    "for count, csv_path in enumerate(glob.glob('./data/ready_to_extract_sub_dataset_*.csv')):\n",
    "    print(count+1)\n",
    "    df = pd.read_csv(csv_path)    \n",
    "    df[[\"f {}\".format(i+1) for i in range(4096) ]] = np.nan\n",
    "    data = My_Custom_Generator(df['OriginalURL'].values, 94)    \n",
    "    for batch in tqdm(data, desc =\"Executed task\"):\n",
    "        features = fe.extract_batch([sub[0] for sub in batch])\n",
    "        df.loc[[df.index[df['OriginalURL'] == x][0] for x in [sub[1] for sub in batch]],[\"f {}\".format(i+1) for i in range(4096) ]] = features\n",
    "        df = df[~df['OriginalURL'].isin(data.empty_images)]\n",
    "    df.to_csv('./data/dataset_with_features/extracted_features_sub_dataset_{}.csv'.format(count+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
